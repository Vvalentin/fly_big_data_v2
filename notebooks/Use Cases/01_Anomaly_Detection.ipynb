{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dc7cd0b",
   "metadata": {},
   "source": [
    "# Use Case: Context-Aware Anomaly Detection im zivilen Luftraum\n",
    "\n",
    "### 1. Die physikalische Ausgangslage\n",
    "In der Luftfahrt unterliegen alle Bewegungen strengen physikalischen Gesetzen. Obwohl jedes Luftfahrzeug ein individuelles Profil hat, ergibt sich in der Masse ein stabiles Muster.\n",
    "\n",
    "Es gelten fundamentale Regeln der Aerodynamik:\n",
    "* **H√∂he & Geschwindigkeit:** In d√ºnnerer Luft (hohe Flugh√∂he) m√ºssen Flugzeuge schneller fliegen, um gen√ºgend Auftrieb zu erzeugen.\n",
    "\n",
    "* **Start & Landung:** Nahe am Boden sind Flugzeuge zwangsl√§ufig langsamer.\n",
    "\n",
    "**Realistische Benchmarks f√ºr \"Normalit√§t\":**\n",
    "* **Reiseflugh√∂he:** Zivile Jets operieren meist zwischen **9.000m und 12.000m**.\n",
    "* **Reisegeschwindigkeit:** √úblich sind **800 bis 950 km/h**.\n",
    "* **Stall Speed:** Die meisten Verkehrsflugzeuge ben√∂tigen mind. **200-300 km/h**, um stabil zu fliegen.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Das Ziel: Anomalie-Erkennung\n",
    "Wir nutzen den **Isolation Forest**-Algorithmus (Unsupervised Learning), um Datenpunkte zu finden, die massiv von dieser \"Norm\" abweichen. Dabei suchen wir zwei Arten von Ausrei√üern:\n",
    "\n",
    "1.  **Technische Anomalien:** Sensorfehler, bei denen unrealistische Werte √ºbertragen werden (z. B. 10 km/h in 10.000m H√∂he).\n",
    "2.  **Operative Anomalien:** Luftfahrzeuge, die sich am physikalischen Limit bewegen (z. B. Kampfjets im Tiefflug oder extrem langsame Objekte).\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Data Enrichment & Context-Awareness\n",
    "Eine rein statistische Analyse hat eine Schw√§che: Sie kennt den Unterschied zwischen einem **Airbus A320** und einem **Hubschrauber** nicht. Ein Hubschrauber, der mit 0 km/h schwebt, w√ºrde von einem \"dummen\" Algorithmus als Absturz (Anomalie) markiert werden.\n",
    "\n",
    "Um dies zu beheben, integrieren wir eine **zweite Datenquelle**.\n",
    "\n",
    "**Die Datenbasis (Data Engineering):**\n",
    "Wir nutzen die **OpenSky Aircraft Database**, die wir zuvor √ºber unsere Pipeline (`aircraft_type_ingest_s3.py`) automatisiert ingestiert und als performante **Parquet-Datei** (`aircraft_database.parquet`) bereitgestellt haben.\n",
    "\n",
    "**Der Kontext-Join:**\n",
    "√úber die eindeutige Transponder-ID (**`icao24`**) verkn√ºpfen wir die Positionsdaten mit den Stammdaten:\n",
    "* `manufacturerName` (z.B. Airbus, Robinson)\n",
    "* `model` (z.B. A320, R44)\n",
    "* `categoryDescription` (z.B. Rotorcraft, Glider)\n",
    "\n",
    "**Die Forschungsfrage:**\n",
    "*Ist der gefundene Ausrei√üer ein physikalischer Fehler (z.B. ein Jet, der zu langsam ist) oder einfach ein Hubschrauber, der sich f√ºr seinen Typ v√∂llig normal verh√§lt?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ca9d32",
   "metadata": {},
   "source": [
    "### Zelle 1: Daten laden & Visualisieren\n",
    "\n",
    "Diese Zelle bereitet die Analyse-Basis vor und f√ºhrt einen ersten Plausibilit√§ts-Check durch:\n",
    "\n",
    "1.  **Automatischer Import:** Das Skript identifiziert und l√§dt automatisch den **zeitlich aktuellsten** Datensatz aus der Spark-Verarbeitung (`run_*`), um manuelle Pfad-Anpassungen zu vermeiden.\n",
    "2.  **Filterung & Bereinigung:** Es werden nur fliegende Objekte (`onground=False`) betrachtet. Datentypen werden korrigiert und die Geschwindigkeit in `km/h` umgerechnet.\n",
    "3.  **Physik-Visualisierung:** Erstellt ein Streudiagramm (H√∂he vs. Geschwindigkeit) mit atmosph√§rischen Referenzschichten (Troposph√§re/Stratosph√§re) und Grenzlinien (Mt. Everest, Armstrong-Limit). Dies dient dazu, **grobe Datenfehler** sofort visuell von **echten Flugbewegungen** zu unterscheiden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a626c482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Design-Einstellungen\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "print(\"--- 1. LADEN & VISUALISIERUNG ---\")\n",
    "\n",
    "# 1. DATEN LADEN\n",
    "base_path = \"../data/processed/run_*\"\n",
    "if not glob.glob(base_path): base_path = \"../../data/processed/run_*\"\n",
    "latest_run = max(glob.glob(base_path), key=os.path.getctime)\n",
    "print(f\"üìÇ Lade Datensatz: {os.path.basename(latest_run)}\")\n",
    "\n",
    "df = pd.read_parquet(latest_run)\n",
    "\n",
    "# 2. DATEN VORBEREITEN\n",
    "cols_to_fix = ['baroaltitude', 'velocity']\n",
    "for col in cols_to_fix:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "df_clean = df[df['onground'] == 'False'].dropna(subset=cols_to_fix).copy()\n",
    "df_clean['velocity_kmh'] = df_clean['velocity'] * 3.6\n",
    "\n",
    "print(f\"‚úÖ Daten geladen: {len(df_clean):,} Punkte.\")\n",
    "\n",
    "# 3. VISUALISIERUNG MIT KONTEXT\n",
    "print(\"üé® Erstelle Diagramm mit atmosph√§rischen Schichten...\")\n",
    "plt.figure(figsize=(14, 9)) # Etwas h√∂her f√ºr die Schichten\n",
    "\n",
    "# SAMPLE HIER EINSTELLEN!\n",
    "sample_size = min(500000, len(df_clean))\n",
    "df_plot = df_clean.sample(n=sample_size, random_state=42)\n",
    "\n",
    "# A) HINTERGRUND-SCHICHTEN (Atmosph√§re)\n",
    "# Troposph√§re (Wettergeschehen, bis ca 11-12km)\n",
    "plt.axhspan(0, 11000, color='lightblue', alpha=0.1, label='Troposph√§re (Wetter)')\n",
    "# Stratosph√§re (Ruhig, dar√ºber)\n",
    "plt.axhspan(11000, 25000, color='darkblue', alpha=0.05, label='Stratosph√§re')\n",
    "\n",
    "# B) DER PLOT\n",
    "sns.scatterplot(\n",
    "    data=df_plot, \n",
    "    x='velocity_kmh', y='baroaltitude',\n",
    "    color='#2c3e50', alpha=0.3, s=15, edgecolor=None\n",
    ")\n",
    "\n",
    "# C) WICHTIGE LINIEN & TEXTE\n",
    "# 1. Mount Everest (8.848m) - Das h√∂chste Hindernis\n",
    "plt.axhline(y=8848, color='brown', linestyle=':', linewidth=1)\n",
    "plt.text(50, 8900, 'Gipfel Mt. Everest (8.848m)', color='brown', fontsize=9, va='bottom')\n",
    "\n",
    "# 2. Typische Reiseflugh√∂he (ca. 10.000m - 12.000m)\n",
    "plt.axhline(y=10000, color='green', linestyle='--', linewidth=1.5)\n",
    "plt.text(50, 10100, 'Reiseflugh√∂he Jets (~10km)', color='green', fontsize=10, fontweight='bold')\n",
    "\n",
    "# 3. Armstrong-Grenze (ca. 19.000m - Blut kocht, fast Weltraum)\n",
    "# Nur anzeigen, wenn wir Daten in der N√§he haben, sonst wird der Plot zu leer\n",
    "if df_clean['baroaltitude'].max() > 15000:\n",
    "    plt.axhline(y=19000, color='purple', linestyle='-.', linewidth=1)\n",
    "    plt.text(50, 19100, 'Armstrong-Grenze (Blut kocht)', color='purple', fontsize=9)\n",
    "\n",
    "# Labels & Titel\n",
    "plt.title(f\"Geschwindigkeit vs. H√∂he\\nSample von {sample_size:,} Punkten\", fontsize=16, fontweight='bold')\n",
    "plt.xlabel(\"Geschwindigkeit (km/h)\")\n",
    "plt.ylabel(\"H√∂he √ºber NN (Meter)\")\n",
    "plt.ylim(0, max(14000, df_clean['baroaltitude'].max() * 1.05)) # Y-Achse dynamisch, aber mind. bis 14km\n",
    "\n",
    "# Legende f√ºr die Schichten (Trick mit Fake-Elementen)\n",
    "tropo_patch = mpatches.Patch(color='lightblue', alpha=0.3, label='Troposph√§re')\n",
    "strato_patch = mpatches.Patch(color='darkblue', alpha=0.1, label='Stratosph√§re')\n",
    "plt.legend(handles=[tropo_patch, strato_patch], loc='lower right', title=\"Atmosph√§re\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68244633",
   "metadata": {},
   "source": [
    "### Zelle 2: Geografische Analyse der Anomalien\n",
    "\n",
    "In diesem Schritt identifizieren wir statistische Ausrei√üer mittels **Unsupervised Machine Learning** und verorten sie r√§umlich:\n",
    "\n",
    "1.  **Isolation Forest:** Das Modell lernt die \"normale\" Korrelation zwischen H√∂he und Geschwindigkeit auf Basis des gesamten Datensatzes. Es markiert die extremsten **1%** der Datenpunkte als Anomalien (`contamination=0.01`).\n",
    "2.  **Scoring & Ranking:** Jeder Punkt erh√§lt einen **Anomaly Score**. Wir filtern die Top 100 Flugzeuge mit den **st√§rksten Abweichungen** (negativster Score) heraus, um die gravierendsten F√§lle zu isolieren.\n",
    "3.  **Visualisierung:** Die Anomalien werden auf einer Weltkarte (rot) gegen ein Sample des normalen Verkehrs (grau) geplottet. Dies hilft, geografische Muster zu erkennen (z.B. H√§ufung von Sensorfehlern in Regionen ohne Radarabdeckung)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033deb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import warnings\n",
    "\n",
    "# SCHALLD√ÑMPFER\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"--- 2. ANOMALY DETECTION & GEOGRAFISCHE ANALYSE ---\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# SCHRITT A: DAS MACHINE LEARNING MODELL (Isolation Forest)\n",
    "# ---------------------------------------------------------\n",
    "print(\"ü§ñ Trainiere Isolation Forest Modell...\")\n",
    "\n",
    "# 1. Features ausw√§hlen (Worauf achten wir?)\n",
    "# Wir nutzen Geschwindigkeit und H√∂he.\n",
    "features = ['velocity_kmh', 'baroaltitude']\n",
    "X = df_clean[features].fillna(0) # Sicherheitshalber Nullen auff√ºllen\n",
    "\n",
    "# 2. Modell konfigurieren\n",
    "# contamination=0.01: Wir erwarten ca. 1% Anomalien in den Daten\n",
    "model = IsolationForest(n_estimators=100, contamination=0.01, random_state=42)\n",
    "\n",
    "# 3. Trainieren & Vorhersagen\n",
    "model.fit(X)\n",
    "\n",
    "# 4. Ergebnisse speichern\n",
    "df_clean['anomaly_label'] = model.predict(X) # -1 = Anomalie, 1 = Normal\n",
    "df_clean['anomaly_score'] = model.decision_function(X) # Je kleiner (negativer), desto \"schlimmer\"\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# SCHRITT B: DATEN SELEKTIEREN (Die \"Top 100\")\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# Nur die Anomalien (-1) herausfiltern\n",
    "anomalies = df_clean[df_clean['anomaly_label'] == -1].copy()\n",
    "\n",
    "# Koordinaten sicherstellen\n",
    "cols_geo = ['lat', 'lon']\n",
    "for col in cols_geo:\n",
    "    anomalies[col] = pd.to_numeric(anomalies[col], errors='coerce')\n",
    "\n",
    "# WICHTIG: Deduplizierung nach SCHWEREGRAD (Score) statt nach Geschwindigkeit!\n",
    "# Wir sortieren aufsteigend, weil im IsolationForest gilt:\n",
    "# Je tiefer der Score (z.B. -0.20 ist schlimmer als -0.01), desto extremer die Anomalie.\n",
    "unique_anomalies = anomalies.sort_values('anomaly_score', ascending=True).drop_duplicates(subset=['icao24'])\n",
    "\n",
    "# Wir nehmen nur die Top 100 \"schlimmsten\" Flugzeuge f√ºr die Karte\n",
    "top_100_anomalies = unique_anomalies.head(100)\n",
    "\n",
    "print(f\"‚ö†Ô∏è Gefundene Anomalien (Gesamt): {len(anomalies):,}\")\n",
    "print(f\"üî• Top 100 extremste F√§lle (nach Score dedupliziert) werden geplottet.\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# SCHRITT C: DIE KARTE (Visualisierung)\n",
    "# ---------------------------------------------------------\n",
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "# Geo-Projektion\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "# Features (Hintergrund)\n",
    "ax.add_feature(cfeature.LAND, facecolor='#f4f4f4') \n",
    "ax.add_feature(cfeature.OCEAN, facecolor='#eefaff')     \n",
    "ax.add_feature(cfeature.COASTLINE, linewidth=0.8, color='gray')       \n",
    "ax.add_feature(cfeature.BORDERS, linestyle=':', linewidth=0.5, color='gray') \n",
    "\n",
    "# 1. Normaler Verkehr (Kontext)\n",
    "# Wir plotten 1% der \"Normalen\" Daten als grauen Hintergrund\n",
    "df_normal = df_clean[df_clean['anomaly_label'] == 1].sample(frac=0.01, random_state=42)\n",
    "ax.scatter(df_normal['lon'], df_normal['lat'],\n",
    "           c='gray', s=1, alpha=0.3, transform=ccrs.PlateCarree(), label='Normaler Verkehr (Sample)')\n",
    "\n",
    "# 2. Die Top 100 Anomalien\n",
    "scatter = ax.scatter(top_100_anomalies['lon'], top_100_anomalies['lat'],\n",
    "           c=top_100_anomalies['anomaly_score'], # Farbe nach Schweregrad\n",
    "           cmap='Reds_r', # Dunkelrot = Extrem, Hellrot = Weniger extrem\n",
    "           s=100, marker='x', linewidth=2, \n",
    "           transform=ccrs.PlateCarree(), label='Top 100 Anomalien')\n",
    "\n",
    "# Design\n",
    "ax.set_global()\n",
    "plt.colorbar(scatter, label='Anomaly Score (Je negativer, desto extremer)', fraction=0.02, pad=0.04)\n",
    "plt.title(\"Top 100 Anomalien weltweit (Basierend auf Isolation Forest Score)\", fontsize=16, fontweight='bold')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5fb6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Unterdr√ºckt die l√§stigen Warnungen f√ºr sauberen Output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "print(\"--- DATA QUALITY CHECK: DEEP DIVE ---\")\n",
    "\n",
    "# 1. SETUP\n",
    "unique_flights_ids = df_ml['icao24'].unique()\n",
    "total_flights = len(unique_flights_ids)\n",
    "\n",
    "# Filterung der DB\n",
    "df_quality = df_aircraft[df_aircraft['icao24'].isin(unique_flights_ids)].copy()\n",
    "\n",
    "matches_count = len(df_quality)\n",
    "match_rate = (matches_count / total_flights) * 100\n",
    "\n",
    "print(f\"Total Unique Aircraft im Feed: {total_flights:,}\")\n",
    "print(f\"Davon in DB gefunden (Match):  {matches_count:,} ({match_rate:.1f}%)\")\n",
    "\n",
    "# 2. QUALIT√ÑTS-ANALYSE\n",
    "attributes = {\n",
    "    'manufacturerName': 'Hersteller',\n",
    "    'model': 'Modell',\n",
    "    'typecode': 'Typ-Code',\n",
    "    'categoryDescription': 'Kategorie',\n",
    "    'operator': 'Airline/Betreiber'\n",
    "}\n",
    "\n",
    "quality_stats = []\n",
    "\n",
    "for col, label in attributes.items():\n",
    "    if col in df_quality.columns:\n",
    "        valid_count = df_quality[col].replace(r'^\\s*$', np.nan, regex=True).notna().sum()\n",
    "        pct = (valid_count / total_flights) * 100 \n",
    "        quality_stats.append({'Attribute': label, 'Valid_Count': valid_count, 'Percentage': pct})\n",
    "\n",
    "df_stats = pd.DataFrame(quality_stats).sort_values('Percentage', ascending=False)\n",
    "\n",
    "# 3. VISUALISIERUNG\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "colors = ['#2ecc71' if x > 90 else '#f1c40f' if x > 70 else '#e74c3c' for x in df_stats['Percentage']]\n",
    "\n",
    "# FIX: hue und legend=False hinzugef√ºgt\n",
    "ax = sns.barplot(\n",
    "    data=df_stats, \n",
    "    x='Percentage', \n",
    "    y='Attribute', \n",
    "    hue='Attribute',  # <--- Hier war der Fehler\n",
    "    palette=colors,\n",
    "    legend=False      # <--- Verhindert doppelte Legende\n",
    ")\n",
    "\n",
    "for i, v in enumerate(df_stats['Percentage']):\n",
    "    ax.text(v + 1, i, f\"{v:.1f}%\", color='black', va='center', fontweight='bold')\n",
    "\n",
    "plt.title(f\"Datenqualit√§t: Metadaten-Vollst√§ndigkeit \\n(Basis: {total_flights:,} Flugzeuge)\", fontsize=15)\n",
    "plt.xlabel(\"Abdeckung in %\")\n",
    "plt.ylabel(\"\")\n",
    "plt.xlim(0, 115) \n",
    "plt.axvline(x=100, color='grey', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. TEXT-FAZIT\n",
    "print(\"\\n--- FAZIT ZUR DATENQUALIT√ÑT ---\")\n",
    "for index, row in df_stats.iterrows():\n",
    "    missing_pct = 100 - row['Percentage']\n",
    "    print(f\"‚Ä¢ {row['Attribute']}: {row['Percentage']:.1f}% vorhanden (Fehlt bei {missing_pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0debba68",
   "metadata": {},
   "source": [
    "### Zelle 4: Detail-Analyse: Top 50 identifizierte Anomalien\n",
    "\n",
    "Um die abstrakten Statistik-Werte interpretierbar zu machen, verkn√ºpfen wir sie mit physikalischem Kontext:\n",
    "\n",
    "1.  **Daten-Fusion:** Wir joinen die Bewegungsdaten (Anomalien) mit der **Aircraft Database**, um Hersteller und Modell zu identifizieren.\n",
    "2.  **Qualit√§ts-Filter:** Um Rauschen zu vermeiden, betrachten wir nur **eindeutig identifizierte Flugzeuge**.\n",
    "3.  **Ranking:** Die Tabelle zeigt die **Top 50** der physikalisch auff√§lligsten F√§lle, sortiert nach ihrem **Risk Score**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0829dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "print(\"--- 3. KONTEXT-ANREICHERUNG (Nur identifizierte Flugzeuge) ---\")\n",
    "\n",
    "# Sicherheits-Check\n",
    "if 'unique_anomalies' not in locals():\n",
    "    raise ValueError(\"‚ö†Ô∏è Bitte f√ºhre Zelle 2 aus! Wir brauchen 'unique_anomalies'.\")\n",
    "\n",
    "# 1. STAMMDATEN LADEN\n",
    "db_path = \"../data/external/aircraft_database.parquet\"\n",
    "if not os.path.exists(db_path): db_path = \"../../data/external/aircraft_database.parquet\"\n",
    "df_aircraft = pd.read_parquet(db_path)\n",
    "\n",
    "print(f\"üìò Stammdaten geladen. Verkn√ºpfe mit Anomalien...\")\n",
    "\n",
    "# 2. JOIN & FILTER (Der wichtige Teil)\n",
    "# Wir nehmen ALLE Anomalien, nicht nur die Top 100 von vorhin\n",
    "df_context = pd.merge(unique_anomalies, df_aircraft, on='icao24', how='left')\n",
    "\n",
    "# FILTER: Wir wollen NUR Zeilen, wo Hersteller UND Modell bekannt sind\n",
    "# Das schmei√üt alle \"Unknowns\" raus\n",
    "df_identified = df_context.dropna(subset=['manufacturerName', 'model']).copy()\n",
    "\n",
    "# 3. AUFH√úBSCHEN & SORTIEREN\n",
    "column_mapping = {\n",
    "    'anomaly_score': 'Risk Score',\n",
    "    'icao24': 'ICAO ID',\n",
    "    'manufacturerName': 'Hersteller',\n",
    "    'model': 'Modell',\n",
    "    'typecode': 'Typ',\n",
    "    'velocity_kmh': 'Speed (km/h)',\n",
    "    'baroaltitude': 'H√∂he (m)'\n",
    "}\n",
    "\n",
    "# Spalten ausw√§hlen & umbenennen\n",
    "final_table = df_identified[list(column_mapping.keys())].rename(columns=column_mapping)\n",
    "\n",
    "# Runden\n",
    "final_table['Speed (km/h)'] = final_table['Speed (km/h)'].round(1)\n",
    "final_table['H√∂he (m)'] = final_table['H√∂he (m)'].round(0)\n",
    "final_table['Risk Score'] = final_table['Risk Score'].round(4)\n",
    "\n",
    "# Sortieren: Die schlimmsten Scores nach oben\n",
    "final_table = final_table.sort_values('Risk Score', ascending=True)\n",
    "\n",
    "# Top 50 ausw√§hlen\n",
    "top_50 = final_table.head(50)\n",
    "\n",
    "print(f\"‚úÖ Gefiltert: {len(df_identified)} Anomalien mit bekannten Metadaten.\")\n",
    "print(\"Hier sind die Top 50 identifizierten F√§lle:\")\n",
    "\n",
    "display(top_50.set_index('ICAO ID'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
