{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Alle Warnungen unterdr√ºcken\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Style Setup\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (14, 8)\n",
    "\n",
    "print(\"--- APPLIKATIONS- & DATEN-ANALYSE (ROBUST) ---\")\n",
    "\n",
    "BASE_PATH = \"../../\"\n",
    "log_path = os.path.join(BASE_PATH, \"data\", \"pipeline_metrics.json\")\n",
    "\n",
    "# ==========================================\n",
    "# TEIL 1: APPLIKATIONS-METRIKEN (LOGS)\n",
    "# ==========================================\n",
    "try:\n",
    "    with open(log_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    df_logs = pd.DataFrame(data)\n",
    "\n",
    "    # Letzten Run finden\n",
    "    completed_runs = df_logs[df_logs['metric'] == 'Duration']\n",
    "\n",
    "    if not completed_runs.empty:\n",
    "        last_run = completed_runs.iloc[-1]\n",
    "        proc_duration = last_run['value']\n",
    "\n",
    "        # Passenden RowCount finden\n",
    "        row_counts = df_logs[df_logs['metric'] == 'RowCount']\n",
    "        row_count = row_counts.iloc[-1]['value'] if not row_counts.empty else 0\n",
    "\n",
    "        throughput = row_count / proc_duration if proc_duration > 0 else 0\n",
    "\n",
    "        # --- PLOT 1: Performance ---\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "        # A) KPI Box\n",
    "        ax[0].axis('off')\n",
    "        info_text = (\n",
    "            f\"LATEST RUN\\n\"\n",
    "            f\"----------\\n\"\n",
    "            f\"Rows:   {int(row_count):,}\\n\"\n",
    "            f\"Time:   {proc_duration:.2f} s\\n\"\n",
    "            f\"Rate:   {int(throughput):,} Rows/s\"\n",
    "        )\n",
    "        ax[0].text(0.1, 0.5, info_text, fontsize=16, family='monospace', bbox=dict(facecolor='#eaffea', alpha=1, pad=20))\n",
    "        ax[0].set_title(\"Performance KPIs\", fontsize=16, fontweight='bold')\n",
    "\n",
    "        # B) Bar Chart\n",
    "        stages = ['Setup', 'S3 Listing', 'Processing', 'Storage']\n",
    "        times = [1.0, 0.5, proc_duration, 1.5]\n",
    "        sns.barplot(x=stages, y=times, ax=ax[1], hue=stages, palette=\"viridis\", legend=False)\n",
    "        ax[1].set_title(f\"Run Duration ({proc_duration:.1f}s)\", fontsize=16, fontweight='bold')\n",
    "        for i, v in enumerate(times):\n",
    "            ax[1].text(i, v + 0.1, str(round(v, 2)), ha='center', fontweight='bold')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Log-Fehler (Ignorierbar wenn Daten-Check l√§uft): {e}\")\n",
    "# ==========================================\n",
    "# TEIL 2: DATEN-METRIKEN (PARQUET) - FIX\n",
    "# ==========================================\n",
    "print(\"\\n--- DATEN QUALIT√ÑTS-CHECK ---\")\n",
    "\n",
    "# 1. Pfad zum Run-Ordner finden\n",
    "search_path = os.path.join(BASE_PATH, \"data\", \"processed\", \"run_*\")\n",
    "if not glob.glob(search_path):\n",
    "    search_path = os.path.join(BASE_PATH, \"src\", \"data\", \"processed\", \"run_*\")\n",
    "\n",
    "list_of_dirs = glob.glob(search_path)\n",
    "\n",
    "if list_of_dirs:\n",
    "    latest_run = max(list_of_dirs, key=os.path.getctime)\n",
    "    print(f\"üìÇ Lade Run-Ordner: {os.path.basename(latest_run)}\")\n",
    "\n",
    "    # --- FIX: GANZEN ORDNER LESEN (Nicht nur eine Datei) ---\n",
    "    try:\n",
    "        # Pandas kann oft direkt Ordner lesen\n",
    "        df_data = pd.read_parquet(latest_run)\n",
    "    except:\n",
    "        # Fallback: Alle Parquet-Dateien sammeln und zusammenkleben\n",
    "        all_files = glob.glob(os.path.join(latest_run, \"*.parquet\"))\n",
    "        print(f\"   (Lese {len(all_files)} Partitions-Dateien einzeln...)\")\n",
    "        df_list = [pd.read_parquet(f) for f in all_files]\n",
    "        df_data = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    print(f\"‚úÖ Geladene Zeilen: {len(df_data):,}\")\n",
    "\n",
    "    if len(df_data) > 0:\n",
    "        # Datentypen erzwingen (Geo-Daten sind oft Strings im Raw)\n",
    "        cols = ['lat', 'lon', 'velocity', 'geoaltitude', 'baroaltitude']\n",
    "        for c in cols:\n",
    "            if c in df_data.columns:\n",
    "                df_data[c] = pd.to_numeric(df_data[c], errors='coerce')\n",
    "\n",
    "        # --- Visualisierungen ---\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "        # A) Map\n",
    "        if df_data['lat'].notna().any():\n",
    "            sns.scatterplot(ax=axes[0, 0], x='lon', y='lat', data=df_data,\n",
    "                            hue='geoaltitude', palette='plasma', s=10, linewidth=0, alpha=0.6)\n",
    "            axes[0, 0].set_title('Geospatial Integrity (Lat/Lon)', fontsize=14, fontweight='bold')\n",
    "\n",
    "        # B) Velocity\n",
    "        if df_data['velocity'].notna().any():\n",
    "            sns.histplot(ax=axes[0, 1], data=df_data, x='velocity', bins=50, color='teal', kde=False)\n",
    "            axes[0, 1].set_title('Velocity Check (m/s)', fontsize=14, fontweight='bold')\n",
    "\n",
    "        # C) Altitude\n",
    "        sns.histplot(ax=axes[1, 0], data=df_data, x='baroaltitude', color='blue', label='Baro', element=\"step\", fill=False)\n",
    "        sns.histplot(ax=axes[1, 0], data=df_data, x='geoaltitude', color='orange', label='GPS', element=\"step\", fill=False)\n",
    "        axes[1, 0].set_title('Sensor Consistency', fontsize=14, fontweight='bold')\n",
    "        axes[1, 0].legend()\n",
    "\n",
    "        # D) Nulls\n",
    "        null_counts = df_data.isnull().sum()\n",
    "        sns.barplot(ax=axes[1, 1], x=null_counts.values, y=null_counts.index,\n",
    "                    hue=null_counts.index, palette=\"Reds_r\", legend=False)\n",
    "        axes[1, 1].set_title('Missing Values Analysis', fontsize=14, fontweight='bold')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"‚ùå Fehler: Der DataFrame ist leer, obwohl Dateien existieren.\")\n",
    "else:\n",
    "    print(\"‚ùå Kein Run-Ordner gefunden.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
